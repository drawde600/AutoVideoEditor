# Implementation Plan: Automatic Video Highlight Pipeline

**Branch**: `001-auto-highlight-pipeline` | **Date**: 2025-10-25 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/001-auto-highlight-pipeline/spec.md`

**Note**: This plan is generated by the `/speckit.plan` command. See `.specify/templates/commands/plan.md` for the execution workflow.

## Summary

Build a Python-based automatic video editor that processes one or more long MP4 videos into curated highlight reels through a 5-phase pipeline (Segmentation → Ranking → Assembly → Composition → Audio). Each phase produces JSON checkpoints enabling manual overrides and non-destructive editing. The system uses OpenCV for visual analysis (motion, scene changes, composition) and FFmpeg for video/audio manipulation.

**Core Value**: Automates the extraction of interesting segments from multiple drone videos (totaling 2 hours) into a single 3-minute highlight reel, with full manual override capability via JSON checkpoints.

## Technical Context

**Language/Version**: Python 3.11+
**Primary Dependencies**: OpenCV (cv2), FFmpeg (via subprocess/ffmpeg-python wrapper), Python standard library (json, pathlib, argparse, logging)
**Storage**: File-based (MP4 input/output, JSON checkpoints, log files)
**Testing**: pytest for unit/integration tests, test fixtures for sample videos
**Target Platform**: Desktop/Server (Windows, Linux, macOS) - command-line interface
**Project Type**: Single command-line application with library modules
**Performance Goals**: Process 2-hour 1080p video → 3-minute highlight in <15 minutes (SC-001); individual phases <2 minutes (SC-006)
**Constraints**: Videos up to 4 hours, 1080p resolution (SC-004); preserve source quality (SC-005); non-destructive editing (FR-026)
**Scale/Scope**: Single-user CLI tool; processes one video at a time; supports 5 distinct pipeline phases

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

**Status**: No constitution defined yet - proceeding with industry best practices for Python CLI tools:
- Modular design with clear separation of concerns
- Library-first approach (business logic separate from CLI)
- Comprehensive logging and error handling
- Non-destructive operations (preserve source files)
- JSON-based configuration and state persistence

**Post-Design Re-check**: Will validate after Phase 1 design artifacts are complete.

## Project Structure

### Documentation (this feature)

```text
specs/001-auto-highlight-pipeline/
├── spec.md              # Feature specification
├── plan.md              # This file (/speckit.plan command output)
├── research.md          # Phase 0 output - technology decisions
├── data-model.md        # Phase 1 output - entity definitions
├── quickstart.md        # Phase 1 output - usage examples
├── contracts/           # Phase 1 output - JSON schemas
│   ├── checkpoint-phase1.json
│   ├── checkpoint-phase2.json
│   ├── checkpoint-phase3.json
│   ├── checkpoint-phase4.json
│   └── checkpoint-phase5.json
└── tasks.md             # Phase 2 output (/speckit.tasks command)
```

### Source Code (repository root)

```text
src/
├── autovideo/
│   ├── __init__.py
│   ├── models/              # Data entities and validation
│   │   ├── __init__.py
│   │   ├── video_source.py
│   │   ├── segment.py
│   │   ├── checkpoint.py
│   │   └── pipeline_config.py
│   ├── phases/              # Pipeline phase implementations
│   │   ├── __init__.py
│   │   ├── phase1_segmentation.py
│   │   ├── phase2_ranking.py
│   │   ├── phase3_assembly.py
│   │   ├── phase4_composition.py
│   │   └── phase5_audio.py
│   ├── analysis/            # Video analysis utilities
│   │   ├── __init__.py
│   │   ├── motion_detector.py
│   │   ├── scene_detector.py
│   │   └── composition_analyzer.py
│   ├── video/               # Video processing utilities
│   │   ├── __init__.py
│   │   ├── ffmpeg_wrapper.py
│   │   └── video_io.py
│   ├── utils/               # Shared utilities
│   │   ├── __init__.py
│   │   ├── logger.py
│   │   ├── progress.py
│   │   └── validator.py
│   └── cli.py               # Command-line interface
├── main.py                  # Entry point
└── requirements.txt         # Python dependencies

tests/
├── unit/
│   ├── test_models.py
│   ├── test_segmentation.py
│   ├── test_ranking.py
│   ├── test_assembly.py
│   ├── test_composition.py
│   └── test_audio.py
├── integration/
│   ├── test_full_pipeline.py
│   ├── test_checkpoint_override.py
│   └── test_phase_resume.py
└── fixtures/
    ├── sample_video_short.mp4
    ├── sample_video_long.mp4
    └── expected_outputs/

config/
└── logging.yaml             # Logging configuration

output/                      # Created at runtime
├── checkpoints/
├── logs/
└── videos/
```

**Structure Decision**: Single-project structure selected as this is a standalone CLI tool without frontend/backend separation. The `src/autovideo/` package contains all business logic organized by responsibility (models, phases, analysis, video processing, utilities), with a thin CLI wrapper in `cli.py`. This structure supports library-first design and enables future GUI/API integration.

## Complexity Tracking

> No constitution violations identified. Proceeding with straightforward single-project CLI architecture.

## Phase Breakdown

### Phase 0: Research & Technical Decisions

**Objective**: Resolve all technology choices and establish implementation patterns.

**Research Areas**:
1. OpenCV integration patterns for frame analysis
2. FFmpeg subprocess management best practices
3. Motion detection algorithms (frame differencing vs optical flow)
4. Scene change detection techniques (histogram comparison, edge detection)
5. Visual composition scoring heuristics
6. JSON schema validation approaches
7. Progress reporting patterns for long-running processes
8. Python logging configuration for multi-level output

**Output**: `research.md` with decision rationale for each area

### Phase 1: Design & Contracts

**Objective**: Define data models, JSON checkpoint schemas, and integration patterns.

**Deliverables**:

1. **data-model.md**: Entity definitions with fields, validation rules, state transitions
   - VideoSource, Segment, Checkpoint (5 variants), PipelineConfig, ProgressReport, LogFile

2. **contracts/**: JSON schemas for each checkpoint phase
   - Phase 1: Segmentation checkpoint (segments with timestamps, durations)
   - Phase 2: Ranking checkpoint (segments with scores, classifications)
   - Phase 3: Assembly checkpoint (selected segments, ordering)
   - Phase 4: Composition checkpoint (effects, overlays, subtitles)
   - Phase 5: Audio checkpoint (mixing settings, normalization levels)

3. **quickstart.md**: Usage examples
   - Basic: Full pipeline execution
   - Manual override: Edit checkpoint and resume
   - Individual phase: Run single phase with existing checkpoint
   - Logging levels: Adjust verbosity

**Output**: `data-model.md`, `contracts/*.json`, `quickstart.md`

## Architecture Decisions

### Pipeline Orchestration

**Pattern**: Command pattern with phase chaining
- Each phase implements `PhaseInterface` with `execute(config, checkpoint_in) → checkpoint_out`
- Pipeline runner executes phases sequentially or individually based on CLI args
- Checkpoints passed as input/output between phases

### Checkpoint Management

**Pattern**: JSON-based state persistence
- Each phase reads optional input checkpoint (skip recalculation)
- Each phase writes output checkpoint (enable manual override)
- Validation layer ensures checkpoint integrity before use (FR-027)
- Schema validation using JSON Schema or Pydantic models

### Error Handling

**Strategy**: Fail-fast with clear error messages (FR-029)
- Phase failures halt pipeline and report error to user
- Validation errors show specific field/constraint violated
- FFmpeg errors capture stderr and present to user
- No interesting segments → specific error message (FR-007)

### Logging & Observability

**Pattern**: Dual-channel logging (FR-032, FR-033, FR-034)
- Console: Progress updates, phase transitions, warnings
- File: Detailed logs with timestamps, debug info, errors
- Configurable verbosity: minimal, moderate, detailed, verbose
- Default: detailed with progress percentages

### Video Processing Architecture

**Pattern**: Hybrid OpenCV + FFmpeg
- **OpenCV**: Frame extraction, analysis (motion, scenes, composition)
- **FFmpeg**: Video encoding/decoding, assembly, effects, audio mixing
- Frame sampling strategy: Analyze subset of frames (e.g., 1fps) for performance
- Temporary file management: Cleanup intermediate files after phase completion

## Testing Strategy

### Unit Tests
- Models: Validation, serialization, state transitions
- Analysis: Motion/scene detection algorithms with known test videos
- Utilities: Logger, progress reporter, validator

### Integration Tests
- Full pipeline: End-to-end with fixture videos
- Checkpoint override: Modify checkpoint, resume pipeline
- Phase resume: Start from specific phase with existing checkpoints
- Edge cases: Short videos, low-quality videos, corrupted checkpoints

### Test Fixtures
- `sample_video_short.mp4`: 30-second video for quick tests
- `sample_video_long.mp4`: 5-minute video with varied content for realistic tests
- Expected outputs: Known-good highlight reels for regression testing

## Performance Considerations

### Frame Sampling
- Analyze 1 frame per second (1fps) instead of all frames (24-60fps)
- Reduces processing time by 24-60x while maintaining accuracy
- Configurable via `--sample-rate` CLI argument

### Parallel Processing
- Phase 1 segmentation: Process video chunks in parallel (optional optimization)
- Phase 2 ranking: Score segments independently (embarrassingly parallel)
- Initial implementation: Sequential for simplicity

### Memory Management
- Stream video frames instead of loading entire video into memory
- Release OpenCV resources (VideoCapture) after each phase
- Clean up temporary files progressively

## Risk Mitigation

| Risk | Impact | Mitigation |
|------|--------|------------|
| FFmpeg not installed | High - pipeline unusable | Check FFmpeg availability at startup, provide clear installation instructions |
| Large file processing (>10GB) | Medium - memory/performance | Implement streaming, document limitations in README |
| Quality scoring accuracy | Medium - poor highlights | Make algorithm configurable, support manual override via checkpoints |
| Checkpoint corruption | Low - user frustration | JSON schema validation, provide repair/regenerate tools |

## Open Questions

*To be resolved in Phase 0 research:*

1. What specific OpenCV algorithms for motion detection? (Frame differencing vs optical flow)
2. Scene change detection threshold values? (Experimentation needed)
3. Composition scoring formula weights? (Motion 40%, scene changes 30%, composition 30%?)
4. FFmpeg command templates for each operation? (Assembly, transitions, overlays, audio mixing)
5. Progress estimation accuracy? (How to predict remaining time?)

## Dependencies

### External Libraries
- `opencv-python` (cv2): Video frame analysis
- `ffmpeg-python`: Python wrapper for FFmpeg subprocess calls
- `jsonschema` or `pydantic`: JSON validation
- `pytest`: Testing framework
- `click` or `argparse`: CLI argument parsing

### System Requirements
- Python 3.11+
- FFmpeg installed and available in PATH
- Sufficient disk space (2x source video size)

### Optional Dependencies
- `tqdm`: Enhanced progress bars
- `colorlog`: Colored console output
- `pyyaml`: YAML logging configuration

## Next Steps

1. Execute Phase 0: Research & generate `research.md`
2. Execute Phase 1: Design & generate `data-model.md`, `contracts/`, `quickstart.md`
3. Update agent context with technology stack
4. Proceed to `/speckit.tasks` for task breakdown

---

**Plan Status**: Ready for Phase 0 research execution
